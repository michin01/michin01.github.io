
<?DOCTYPE html>
<head>
<link rel = "stylesheet" type = "text/css" href = "style.css">
<title>Michelle Brachman</title>

<link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
<meta name="viewport" content="width=device-width, initial-scale=1.0">


</head>

<body>

<div id='contact-section'>
<h1> Michelle (Ichinco) Brachman, PhD</h1>
<!-- <p> Formerly, Human-Centered AI Research Scientist at IBM Research, Assistant Professor at UMass Lowell</p> -->
</div>
<h2>Summary</h2>
<p>
<img src = '1757942432521.jpg'>

I am an experienced human-computer interaction (HCI) researcher who loves to use qualitative and quantitative methods. I like to understand how people think, learn, and work, design interfaces to improve their experiences, and evaluate those experiences using qualitative and quantitative methods. My goal has been to better understand how people learn about and effectively work with complex and sociotechnical systems. I gain insight into user needs, mental models, perspectives, and workflows using methods like interviews, surveys, and think-aloud studies. I design and prototype systems based on discovered user needs. I evaluate systems through user studies, interviews, and surveys, gathering data such as how people use systems, their cognitive load, trust, and their ability to effectively evaluate the accuracy of AI systems. Throughout my research, I leverage theoretical frameworks, such as cognitive load theory and sensemaking theories, to reason about how people understand and use complex systems. </p>

<p>
My work at IBM Research for the past five years has centered around human-centered, trustworthy, and responsible AI for business users and developers and the future of work. I focused on enabling appropriate trust in AI systems and the impact of generative AI on technical and non-technical workers. As a tenure-track Assistant Professor of Computer Science at UMass Lowell for two years, I led a lab of graduate and undergraduate students researching programmer needs around learning APIs (Application Programming Interfaces). Together, my research over the past seven years has addressed the needs of two main user groups, business users and programmers, in accomplishing their work using complex, sociotechnical tools.
</p>

<p>
Research Interests: human-centered AI, responsible AI, AI developer experience, future-of-work, developer/end-user programmer experience, mental models and learning with complex systems.
</p>

<h2>Projects</h2>


<h3>Improving transparency and appropriate trust of an agentic AI  </h3>
<div>
  <img src = 'agenticchat.png'>
  <p>
    <b>Goal:</b> Understand the kinds of information users need to be able to correctly evaluate the accuracy of an agentic AI system's responses.
  </p>
    <p>
      <b>Methods:</b> Task-based think-aloud user study with 24 participants interacting with an agentic AI chatbot and semi-structured interviews.
    </p>
  <p>
    <b>Findings:</b> Users often put too much trust into an AI system. They are easily misled by the amount of information available (such as a list of sources). Many users do want to know about the agentic AI's capabilities, limitations, and decision-making processes.
  </p>
  <p>
    <b>Impact:</b> Influenced the early design of the end-user interface for <a target="_blank" href="https://beeai.dev"> BeeAI</a>, an open-source platform to build agentic AI systems which won a <a target="_blank" href="https://www.fastcompany.com/91388508/graphic-design-branding-innovation-by-design-2025">Fast Company Innovation by Design Honorable Mention</a>.
  </p>  

</div>

<h3>Discovering current and future generative AI needs of business users</h3>
<div>
<img src = 'useofllms.png'>
  <p>
    <b>Goal:</b> Learn how knowledge workers in an enterprise context use LLMs, how they would like to use them in the future, challenges in using them, and reasons for lack of use.
  </p>
  <p>
    <b>Methods:</b> Survey of 216 knowledge workers and follow-up survey with 107 participants.
  </p>
  <p>
    <b>Findings:</b> We found four key types of use: creating, finding information, getting advice, and automation. Users initially focused on creating content, like drafts of documents or emails. The second survey revealed that use of LLMs was increasing for information-focused tasks like searching and learning. Workers still hoped for more AI support in getting feedback on their work, analysis, and automating tasks. Workers also wanted to use AI for more complex tasks that require domain knowledge and context, but often did not feel that the existing systems were capable in those areas (as of the time the surveys were run). 
  </p>
  <p>
    <b>Impact:</b> Our findings were presented and shared broadly within IBM, informing product and innovation teams and strategy. This work inspired future projects, such as an AI tool for agile epic evaluation, aimed at improving product management workflows. We published this work at <a target="_blank" href="https://dl.acm.org/doi/pdf/10.1145/3757403">ACM CSCW</a> and <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3613905.3650841">ACM CHI</a>. It was also featured in <a target="_blank" href="https://undark.org/2025/09/12/critical-thinking-chatbots/">Undark Magazine</a>.
  </p>  
</div>

<h3>Supporting Product Management Workflows with AI</h3>
<div>

<p>
  <b>Goal:</b> Understand the challenges and needs of product managers during agile epic creation and when using AI to support agile epic evaluation.
</p>
<p>
  <b>Methods:</b> User study and interviews with 17 product managers.
</p>
<p>
  <b>Findings:</b> Participants found value in an AI system for helping them evaluate and prioritize agile epics. However, this kind of system should provide felixibility to support diverse practices and could help organizations be more consistent in their agile practices. Lack of domain knowledge and context are also challenges for AI systems in this space.
</p>
<p>
  <b>Impact:</b> The findings and tool were distributed broadly internally. We also published <a target="_blank" href="https://dl.acm.org/doi/pdf/10.1145/3729176.3729200">a case study </a>at CHIWORK, which won Best Paper.
</p>

<h3>Enabling end-users to generate automation flows using transparency and explanation</h3>
<div>
<img src = 'gofa1.png'>
<img src = 'gofa2.png'>
<p>
  <b>Goal:</b> Understand how explanations can help end-users create correct automation flows using a natural language to automation system.
</p>
<p>
  <b>Methods:</b> Between-subjects user study of creating automation flows with several variations of explanations or without explanations on Amazon Mechanical Turk (252 participants).
</p>
<p>
  <b>Findings:</b> Providing suggestions of terms to add to an utterance based on others users' inputs helpedusers to repair and generate correct flows more than system-focused explanations.
</p>
<p>
  <b>Impact:</b> Findings were integrated into the design of IBM's AppConnect AI-powered natural language to automation product.
</p>
<!-- </div>
<h3>Supporting accurate and fast AI-assisted data labeling</h3>
<div> -->

</div>

</div>
<h2>Publications</h2>
<p> View and access my full publication history on <a target="_blank" href="https://scholar.google.com/citations?hl=en&user=_cFhtU4AAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a>. </p>
<p>Selected Publications and Patents: </p>
<p>2025</p>

<div class='row'>
<div class='column left'> <b>Michelle Brachman</b>, Amina El-Ashry, Casey Dugan, Werner Geyer.
  <i>Current and Future Use of Large Language Models for Knowledge Work. </i> 
 Proceedings of the ACM on Human-Computer Interaction (CSCW).</div>
  <div class='column right'>[<a target="_blank" href ="3613905.3650841.pdf" >local</a>]</div><div class='column right'>[<a target="_blank" href =https://dl.acm.org/doi/pdf/10.1145/3757403 >acm</a>]</div>
</div>

<div class='row'>
<div class='column left'><b>Michelle Brachman</b>, Siya Kunde, Sarah Miller, Ana Fucs, Samantha Dempsey, Jamie Jabbour, Werner Geyer. 
  <i>Building Appropriate Mental Models: What Users Know and Want to Know about an Agentic AI Chatbot. </i> 
  Proceedings of the 30th International Conference on Intelligent User Interfaces. </div>
  <div class='column right'>[<a target="_blank" href =https://dl.acm.org/doi/pdf/10.1145/3708359.3712071 >acm</a>]</div>
</div>
<div class='row'>
<div class='column left'><b>Michelle Brachman</b>, Arielle Goldberg, Andrew Anderson, Stephanie Houde, Michael Muller, Justin D Weisz. 
  <i>Towards Personalized and Contextualized Code Explanations. </i> 
 Adjunct Proceedings of the 33rd ACM Conference on User Modeling, Adaptation and Personalization </div>
  <div class='column right'>[<a target="_blank" href =https://dl.acm.org/doi/abs/10.1145/3708319.3733681 >acm</a>]</div>
</div>
<div class='row'>
<div class='column left'>**Best Paper** Werner Geyer, Jessica He, Daita Sarkar, <b>Michelle Brachman</b>, Chris Hammond, Jennifer Heins, Zahra Ashktorab, Carlos Rosemberg, Charlie Hill
  <i>A Case Study Investigating the Role of Generative AI in Quality Evaluations of Epics in Agile Software Development. </i> 
 Proceedings of the 4th Annual Symposium on Human-Computer Interaction for Work </div>
  <div class='column right'>[<a target="_blank" href =https://dl.acm.org/doi/pdf/10.1145/3729176.3729200 >acm</a>]</div>
</div>


<p>2024</p>

<div class='row'>
<div class='column left'> <b>Michelle Brachman</b>, Amina El-Ashry, Casey Dugan, Werner Geyer.
  <i>How Knowledge Workers Use and Want to Use LLMs in an Enterprise Context. </i> 
 Extended Abstracts of the CHI Conference on Human Factors in Computing Systems </div>
  <div class='column right'>[<a target="_blank" href ="3613905.3650841.pdf" >local</a>]</div><div class='column right'>[<a target="_blank" href =https://dl.acm.org/doi/abs/10.1145/3613905.3650841 >acm</a>]</div>
</div>

<p>2023</p>
  
<div class='row'>
<div class='column left'> <b>Michelle Brachman</b>, Qian Pan, Hyo Jin Do, Casey Dugan, Arunima Chaudhary, J Johnson, Priyanshu Rai, Tathagata Chakraborti, Thomas Gschwind, Jim A Laredo, Christoph Miksovic Czasch, Paolo Scotton, Kartik Talamadupula, Gegi Thomas. 
  <i>Follow the Successful Herd: Towards Explanations for Improved Use and Mental Models of Natural Language Systems. </i> 
 Proceedings of the 30th International Conference on Intelligent User Interfaces </div>
  <div class='column right'>[<a target="_blank" href =https://dl.acm.org/doi/pdf/10.1145/3581641.3584088 >acm</a>]</div>
</div>

<p>2022</p>
<div class='row'>
<div class='column left'> <b>Michelle Brachman</b>, Zahra Ashktorab, Michael Desmond, Evelyn Duesterwald, Casey Dugan, Narendra Nath Joshi, Qian Pan, Aabhas Sharma. 
  <i>Reliance and Automation for Human-AI Collaborative Data Labeling Conflict Resolution. </i> 
Proceedings of the ACM on Human-Computer Interaction (CSCW) </div>
  <div class='column right'>[<a target="_blank" href ="3555212.pdf" >local</a>]</div><div class='column right'>[<a target="_blank"  href =https://dl.acm.org/doi/abs/10.1145/3555212 >acm</a>]</div>
</div>

  
<p>2020</p>

<div class='row'>
<div class='column left'>**Best Paper** Gao Gao, Finn Voichick, <b>Michelle Ichinco</b>, and Caitlin Kelleher. <i>Exploring Programmers' API Learning Processes: Collecting Web Resources as External Memory.</i> 2020 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC), Dunedin, New Zealand, 2020, pp. 1-10.</div>
<div class='column right'>[<a target="_blank" href ="Exploring_Programmers_API_Learning_Processes.pdf" >local</a>]</div> <div class='column right'>[<a target="_blank" href =https://doi.org/10.1109/VL/HCC50065.2020.9127274 >ieee</a>]</div>
</div>

<p>2019</p>
<div class='row'>
<div class='column left'> <b>Michelle Ichinco</b> and Caitlin Kelleher. <i> Open-Ended Novice Programming Behaviors and their Implications for Supporting Learning </i>. 2019 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC), pp 45-53.</div><div class='column right'>[<a href ="Ichinco-vlhcc2019.pdf">local</a>][<a href="https://ieeexplore.ieee.org/abstract/document/8818886">ieee</a>] </div>
</div>
<div class='row'>
<div class='column left'>Caitlin Kelleher and <b>Michelle Ichinco</b>. <i>Towards a Model of API Learning </i>. 2019 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC), pp 163 - 168.</div><div class='column right'> [<a href ="kelleher-ichinco-vlhcc-2019.pdf">local</a>][<a href="https://doi.org/10.1109/VLHCC.2019.8818850">ieee</a>]</div></div>

<p>2018</p>
<div class='row'>
<div class='column left'><b> Michelle Ichinco</b> and Caitlin Kelleher. <i>Semi-automatic suggestion generation for young novice programmers in an open-ended context </i>. Proceedings of the 17th ACM Conference on Interaction Design and Children
pp 405-412.</div> <div class='column right'> [<a target="_blank" href ="ichinco-semi-automatically.pdf" >local</a>][<a target="_blank"  href="https://dl.acm.org/doi/abs/10.1145/3202185.3202762">acm</a>]</div>
</div>
<p>2017</p>
<div class='row'>
<div class='column left'><b>Michelle Ichinco</b>, Wint Hnin, and Caitlin Kelleher. <i> Suggesting API Usage to Novice Programmers with the Example Guru</i> Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, pp 1105-1117.</div><div class='column right'>[<a target="_blank" href ="chi-2017-final.pdf">local</a>][<a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3025453.3025827">acm</a>]</div>
</div>
<div class='row'>
<div class='column left'><b>Michelle Ichinco</b> and Caitlin Kelleher. <i> Towards Better Code Snippets: Exploring How Code Snippet Recall Differs with Programming Experience</i> IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC), pp 37-41.</div><div class='column right'> [<a target="_blank" href ="ichinco-vlhcc2017.pdf" >local</a>][<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/8103448">ieee</a>]</div></div>

<div class='row'>
<div class='column left'>**Best Paper** Wint Hnin, <b>Michelle Ichinco</b>, and Caitlin Kelleher. <i>An Exploratory Study of the Usage of Different Educational Resources in the Wild</i>. IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC), pp 181-189.</div> <div class='column right'> [<a target="_blank" href ="hnin-ichinco-vlhcc2017.pdf" >local</a>][<a target="_blank"  href="https://ieeexplore.ieee.org/abstract/document/8103466">ieee</a>]</div>
</div>

<!-- <div class='row'>
<div class='column left'><b>Michelle Ichinco</b>, Kyle Harms, and Caitlin Kelleher. <i>Towards Understanding Successful Novice Example Use in Blocks-Based Programming</i> Journal of Visual Languages and Sentient Systems, pp 101-118.</div><div class='column right'> [<a target="_blank" ="http://www.ksiresearch.org/vlss/journal/VLSS2017/vlss-2017-ichinco-harms-kelleher.pdf">KSI</a>]</div>
</div> -->
<!-- <p>2015</p>
<div class='row'>
<div class='column left'><b>Michelle Ichinco</b> and Caitlin Kelleher. <i>Exploring novice programmer example use</i>.2015 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC), pp. 63-71.</div><div class='column right'> [<a target="_blank" href ="vlhcc2015.pdf">local</a>][<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/7357199">ieee</a>]</div>
</div>

<p>2013</p>
<div class='row'>
<div class='column left'><b>Michelle Ichinco</b> and Caitlin Kelleher. <i> Towards generalizing expert programmers' suggestions for novice programmers</i>. Visual Languages and Human-Centric Computing (VL/HCC), 2013 IEEE Symposium on, pp. 143-150.</div><div class='column right'> [<a target="_blank" href ="vlhcc2013.pdf" >local</a>][<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/6645259">ieee</a>]</div>
</div> -->



</body>
</html>
